name: End-to-end tests

concurrency:
  group: ${{ github.head_ref }}${{ github.ref }}-integration-tests
  cancel-in-progress: true

on:
  pull_request:
  push:
    branches:
      - "main"
  workflow_dispatch:

defaults:
  run:
    shell: bash
    working-directory: "tests/mediator-integration-tests"

jobs:
  run-integration-tests:
    name: "Run integration tests"
    runs-on: ubuntu-latest
    env:
      REPORTS_DIR: "tests/mediator-integration-tests/target/site/serenity"
    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Setup Java and Scala
        uses: olafurpg/setup-scala@v13
        with:
          java-version: openjdk@1.11

      - name: Setup Gradle
        uses: gradle/gradle-build-action@v2

      - name: Setup Node
        uses: actions/setup-node@v3
        with:
          node-version: "lts/*"

      - name: Login to GitHub Container Registry
        uses: docker/login-action@v2
        with:
          registry: ghcr.io
          username: ${{ secrets.ATALA_GITHUB_ACTOR }}
          password: ${{ secrets.ATALA_GITHUB_TOKEN }}

      - name: Install Compose
        uses: ndeloof/install-compose-action@v0.0.1
        with:
          version: v2.12.2 # defaults to 'latest'
          legacy: true    # will also install in PATH as `docker-compose`

      - name: Build local version of Mediator Agent
        env:
          MEDIATOR_PATH: "../.."
          GITHUB_ACTOR: ${{ secrets.ATALA_GITHUB_ACTOR }}
          GITHUB_TOKEN: ${{ secrets.ATALA_GITHUB_TOKEN }}
        run: |
          cd "${MEDIATOR_PATH}" || exit 129
          NODE_OPTIONS=--openssl-legacy-provider sbt -mem 2048 -J-Xmx5120m docker:publishLocal
          MEDIATOR_VERSION=$(cut version.sbt -d '=' -f2 | tr -d '" ')
          echo ${MEDIATOR_VERSION}

      - name: Start Mediator
        uses: isbang/compose-action@v1.4.1
        with:
          compose-file: "./docker-compose.yml"
          compose-flags: ""
          up-flags: "--wait"
          down-flags: "--volumes"

      - name: Run e2e tests
        env:
          GITHUB_ACTOR: ${{ secrets.ATALA_GITHUB_ACTOR }}
          GITHUB_TOKEN: ${{ secrets.ATALA_GITHUB_TOKEN }}
          ATALA_GITHUB_ACTOR: ${{ secrets.ATALA_GITHUB_ACTOR }}
          ATALA_GITHUB_TOKEN: ${{ secrets.ATALA_GITHUB_TOKEN }}
          MEDIATOR_PEER_DID: "did:peer:2.Ez6LSghwSE437wnDE1pt3X6hVDUQzSjsHzinpX3XFvMjRAm7y.Vz6Mkhh1e5CEYYq6JBUcTZ6Cp2ranCWRrv7Yax3Le4N59R6dd.SeyJ0IjoiZG0iLCJzIjoiaHR0cHM6Ly9rOHMtaW50LmF0YWxhcHJpc20uaW8vbWVkaWF0b3IiLCJyIjpbXSwiYSI6WyJkaWRjb21tL3YyIl19"
        continue-on-error: true
        run: |
          ./gradlew test || true
          ./gradlew reports

#      - name: Update X-Ray test execution
#        uses: ./.github/actions/upload-to-xray
#        if: github.ref_name == 'main'
#        with:
#          username: ${{ secrets.XRAY_CLIENT_ID }}
#          password: ${{ secrets.XRAY_CLIENT_SECRET }}
#          json: "tests/e2e-tests/target/serenity-reports/cucumber_report.json"
#          execution_tag: ${{ env.XRAY_EXECUTION_TAG_LOCALHOST }}

      - name: Upload artifacts
        uses: actions/upload-artifact@v2
        with:
          name: e2e-tests-result
          path: ${{ env.REPORTS_DIR }}

      - name: Publish e2e test Results
        if: always()
        id: publish-unit-tests
        uses: EnricoMi/publish-unit-test-result-action@v2
        with:
          junit_files: "${{ env.REPORTS_DIR }}/SERENITY-JUNIT-*.xml"
          comment_title: "Integration Test Results"
          check_name: "Integration Test Results"

      - name: Extract test results
        id: analyze_test_results
        if: github.ref_name == 'main'
        run: |
          JSON_RESULTS="target/site/serenity/serenity-summary.json"
          CONCLUSION=failure
          TOTAL_TESTS=0
          FAILED_TESTS=0
          SKIPPED_TESTS=0
          TESTS_WITH_ERRORS=0
          if [ -f "${JSON_RESULTS}" ]; then
            TOTAL_TESTS="$(cat ${JSON_RESULTS} | jq '.results.counts.total')"
            PENDING_TESTS="$(cat ${JSON_RESULTS} | jq '.results.counts.pending')"
            SKIPPED_TESTS="$(cat ${JSON_RESULTS} | jq '.results.counts.skipped')"
            IGNORED_TESTS="$(cat ${JSON_RESULTS} | jq '.results.counts.ignored')"
            FAILED_TESTS="$(cat ${JSON_RESULTS} | jq '.results.counts.failure')"
            TESTS_WITH_ERRORS="$(cat ${JSON_RESULTS} | jq '.results.counts.error')"
            if [[ ${FAILED_TESTS} == 0 && ${TESTS_WITH_ERRORS} == 0 ]] ; then
              CONCLUSION=success
            fi
          fi
          {
            echo "slack_report_failure=${SLACK_REPORT_FAILURE}";
            echo "conclusion=${CONCLUSION}";
            echo "tests=${TOTAL_TESTS}";
            echo "failures=${FAILED_TESTS}";
            echo "errors=${TESTS_WITH_ERRORS}";
            echo "pending=${PENDING_TESTS}";
            echo "skipped=${SKIPPED_TESTS}";
            echo "ignored=${IGNORED_TESTS}";
          } >> "$GITHUB_OUTPUT"

#      - name: Slack Notification
#        if: github.ref_name == 'main' && steps.analyze_test_results.outputs.conclusion == 'failure'
#        uses: rtCamp/action-slack-notify@v2
#        env:
#          SLACK_COLOR: ${{ steps.analyze_test_results.outputs.conclusion }}
#          SLACK_MESSAGE: |
#            Total: ${{ steps.analyze_test_results.outputs.tests }}
#            Failed: ${{ steps.analyze_test_results.outputs.failures }}
#            Errors in tests: ${{ steps.analyze_test_results.outputs.errors }}
#            Skipped (known bugs): ${{ steps.analyze_test_results.outputs.skipped }}
#          SLACK_TITLE: "Mediator Integration tests: ${{ steps.analyze_test_results.outputs.conclusion }}"
#          SLACK_USERNAME: circleci
#          SLACK_WEBHOOK: ${{ secrets.E2E_TESTS_SLACK_WEBHOOK }}
